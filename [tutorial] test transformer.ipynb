{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Iterable, List\n",
    "from model import Transformer\n",
    "from data import fr_to_en\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토크나이징에 활용할 Vocab 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 불러오기\n",
    "# Fr -> En 번역을 위한 데이터셋(Multi-30k) 활용\n",
    "fr_data = utils.open_text_set(\"data/training/train.fr\")\n",
    "eng_data = utils.open_text_set(\"data/training/train.en\")\n",
    "\n",
    "# Vocab 만들기 / 관련 함수는 utils.py 참조\n",
    "try : \n",
    "  vocab_transform, token_transform = utils.make_vocab(fr_data, eng_data)\n",
    "except :  \n",
    "  # 오류 발생 시 spacy 설치 필요\n",
    "\n",
    "  # spacy tokenizer 다운로드(en,fr)\n",
    "  import spacy.cli\n",
    "  spacy.cli.download(\"en_core_web_sm\")\n",
    "  spacy.cli.download(\"fr_core_news_sm\")\n",
    "  vocab_transform, token_transform = utils.make_vocab(fr_data, eng_data)\n",
    "\n",
    "# param\n",
    "SRC_LANGUAGE = \"fr\"\n",
    "TGT_LANGUAGE = \"en\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `[tutorial] training`에서 학습한 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Parameters\n",
      "--------------------------------------------------\n",
      "{'src_vocab_size': 11509, 'trg_vocab_size': 10837, 'src_pad_idx': 1, 'trg_pad_idx': 1, 'embed_size': 512, 'num_layers': 3, 'forward_expansion': 2, 'heads': 8, 'dropout': 0.1, 'device': 'cpu', 'max_length': 140}\n",
      "--------------------------------------------------\n",
      "현재 devicde 설정값은 : \"cpu\" 입니다. 변경을 희망하실 경우 config/transformer.json을 수정해주세요.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with open('config/transformer.json', 'r') as file:\n",
    "    param = json.load(file)\n",
    "    print('Model_Parameters')\n",
    "    print('-'*50)\n",
    "    print(param)  \n",
    "\n",
    "# multi-30k 데이터를 20번 epoch한 모델 불러오기\n",
    "model = Transformer(**param)\n",
    "model.load_state_dict(torch.load('model/model.pth'))\n",
    "\n",
    "# 모델 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "device = model.device\n",
    "\n",
    "print('-'*50)\n",
    "print(f'현재 devicde 설정값은 : \"{model.device}\" 입니다. 변경을 희망하실 경우 config/transformer.json을 수정해주세요.')\n",
    "print('-'*50)\n",
    "\n",
    "# loss_fn\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 테스트\n",
    "\n",
    "* 아래 구현 된 test 함수를 통해 Transformer의 실제 문제 예측 과정을 이해할 수 있음.\n",
    "\n",
    "* 모델은 한 번의 하나의 토큰을 생산하며 < bos > token을 시작으로 다음 토큰을 예측해 < eos > 토큰이 생성될때까지 반복 함.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : Un adolescent a un anneau argenté saillant de son nez.\n",
      "모델예측 : A little boy is holding a piece of a large white shirt is holding\n",
      "정답 : A teenage boy has a silver ring protruding from his nose.\n",
      "\n",
      "주의! 29,000개의 제한된 데이터로 학습을 수행했으므로 완벽한 예측이 불가능함.\n"
     ]
    }
   ],
   "source": [
    "# token을 단어로 바꾸기 위한 dict 생성, vocab의 key와 value 위치 변경\n",
    "# 아래 helper 함수에서 활용됨.\n",
    "decoder_en = {v:k for k,v in vocab_transform['en'].get_stoi().items()}\n",
    "decoder_fr = {v:k for k,v in vocab_transform['fr'].get_stoi().items()}\n",
    "\n",
    "def tokenizing_src(input_data:str) : \n",
    "    # input_data_tokenizing\n",
    "    token_data = token_transform['fr'](input_data)\n",
    "    vocab_src = vocab_transform['fr'](token_data)\n",
    "    tokenized_src = [2] + vocab_src + [3]\n",
    "    return tokenized_src\n",
    "\n",
    "def select_random_item() :\n",
    "    num = torch.randint(1,29000,(1,)).item()\n",
    "\n",
    "    return fr_data[num], fr_data[num]\n",
    "\n",
    "def test(model) :\n",
    "    '''\n",
    "    * validation은 문제와 정답이 모두 주어진다면 test는 문제만 제공하는 상황임.\n",
    "\n",
    "    * test 함수를 통해 Transformer의 실제 문제 예측 과정을 이해할 수 있음.\n",
    "\n",
    "    * Transformer는 문제와 정답이 있다면 답을 구하는 과정을 병렬적으로 수행할 수 있음.\n",
    "\n",
    "    * 하지만 테스트에서는 정답이 주어지지 않으므로 한 번의 하나의 토큰을 생산함.\n",
    "\n",
    "    * < bos > token을 시작으로 다음 토큰을 예상하며 < eos > 토큰이 생성될때까지 반복적으로 예측을 수행하게 되는 알고리즘이 필요함.\n",
    "\n",
    "    * 아래의 test 함수를 다뤄보면서 Transformer의 데이터 처리 과정을 이해할 수 있음.\n",
    "\n",
    "    '''\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # 임의의 훈련 데이터 선별\n",
    "    fr_item, en_item = select_random_item()\n",
    "    \n",
    "    print('입력 :', fr_item)\n",
    "\n",
    "    # Input Data 토크나이징 \n",
    "    tokenized_input = tokenizing_src(fr_item)\n",
    "    max_length = int(len(tokenized_input) * 1.2)\n",
    "\n",
    "    # src Tensor에 Token 저장\n",
    "    src = torch.LongTensor(tokenized_input).unsqueeze(0).to(device)\n",
    "\n",
    "    # trg Tensor 생성(1, max_length)\n",
    "    trg = torch.zeros(1,max_length).type_as(src.data).to(device)\n",
    "\n",
    "    # src encoding\n",
    "    enc_src = model.encode(src)\n",
    "\n",
    "    next_trg = 2 # 문장 시작 <bos> idx\n",
    "\n",
    "    # 문장 예측 시작\n",
    "    for i in range(0,max_length) :\n",
    "        trg[0][i] = next_trg # token 저장\n",
    "\n",
    "        logits = model.decode(src,trg,enc_src) # output 산출\n",
    "\n",
    "        prd = logits.squeeze(0).max(dim=-1, keepdim=False)[1] # 예측 단어 중 max 추출\n",
    "        next_word = prd.data[i] # i 번째 위치한 단어 추출\n",
    "        next_trg = next_word.item() \n",
    "        if next_trg == 3 :\n",
    "            # <eos> 나오면 종료\n",
    "            trg[0][i] = next_trg\n",
    "            break\n",
    "    \n",
    "    # <pad> 제거\n",
    "    if 3 in trg[0] :\n",
    "        eos_idx = int(torch.where(trg[0] == 3)[0][0])\n",
    "        trg = trg[0][:eos_idx].unsqueeze(0)\n",
    "    else :\n",
    "        pass\n",
    "\n",
    "    # 번역\n",
    "    translation = [decoder_en[i] for i in trg.squeeze(0).tolist()]\n",
    "    print('모델예측 :',' '.join(translation[1:]))\n",
    "    \n",
    "\n",
    "    print('정답 :', en_item)\n",
    "    print('')\n",
    "    print('주의! 29,000개의 제한된 데이터로 학습을 수행했으므로 완벽한 예측이 불가능함.')\n",
    "\n",
    "\n",
    "\n",
    "test(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (default, Jun 13 2022, 17:35:03) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
