{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Iterable, List\n",
    "from model import Transformer\n",
    "from data import fr_to_en\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocab 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 불러오기\n",
    "# Fr -> En 번역을 위한 데이터셋(Multi-30k) 활용\n",
    "fr_train = utils.open_text_set(\"data/training/train.fr\")\n",
    "en_train = utils.open_text_set(\"data/training/train.en\")\n",
    "\n",
    "# Vocab 만들기 / 관련 함수는 utils.py 참조\n",
    "try : \n",
    "  vocab_transform, token_transform = utils.make_vocab(fr_train, en_train)\n",
    "except :  \n",
    "  # 오류 발생 시 spacy 설치 필요\n",
    "\n",
    "  # spacy tokenizer 다운로드(en,fr)\n",
    "  import spacy.cli\n",
    "  spacy.cli.download(\"en_core_web_sm\")\n",
    "  spacy.cli.download(\"fr_core_news_sm\")\n",
    "  vocab_transform, token_transform = utils.make_vocab(fr_train, en_train)\n",
    "\n",
    "# param\n",
    "SRC_LANGUAGE = \"fr\"\n",
    "TGT_LANGUAGE = \"en\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습한 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Parameter\n",
      "{'src_vocab_size': 11509, 'trg_vocab_size': 10837, 'src_pad_idx': 1, 'trg_pad_idx': 1, 'embed_size': 512, 'num_layers': 3, 'forward_expansion': 2, 'heads': 8, 'dropout': 0.1, 'device': 'cpu', 'max_length': 140}\n",
      "--------------------------------------------------\n",
      "현재 devicde 설정값은 : \"cpu\" 입니다. 변경을 희망하실 경우 config/transformer.json을 수정해주세요.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "with open('config/transformer.json', 'r') as file:\n",
    "    param = json.load(file)\n",
    "    print('Model_Parameter')\n",
    "    print(param)    \n",
    "model = Transformer(**param)\n",
    "\n",
    "# model 불러오기\n",
    "model.load_state_dict(torch.load('model/model.pth'))\n",
    "\n",
    "# 모델 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "\n",
    "device = model.device\n",
    "\n",
    "print('-'*50)\n",
    "print(f'현재 devicde 설정값은 : \"{model.device}\" 입니다. 변경을 희망하실 경우 config/transformer.json을 수정해주세요.')\n",
    "print('-'*50)\n",
    "\n",
    "# loss_fn\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "► Dataset is \"validation\"\n",
      "\n",
      "2번째 batch에 있는 0번째 문장 예측 결과 확인\n",
      "src :  Un chien noir dans l' herbe , tenant un objet en plastique blanc dans sa gueule .\n",
      "prd :  A black dog is in the grass with a microphone bench guitar in a mouth . <eos> <eos> <eos> . . . . . . . . . . . .\n",
      "trg :  A black dog standing in some grass holding a white plastic item in its mouth .\n",
      "\n",
      "\n",
      "4번째 batch에 있는 0번째 문장 예측 결과 확인\n",
      "src :  Le chien noir saute au-dessus de l' eau vers un frisbee flottant près d' un bateau .\n",
      "prd :  The black dog and on the beach with the body in . a boat . <eos> . . . . . . . <eos> . . . . . . . . .\n",
      "trg :  The black dog jumps above the water towards a Frisbee floating near a boat .\n",
      "\n",
      "\n",
      "6번째 batch에 있는 0번째 문장 예측 결과 확인\n",
      "src :  Un homme avec un badge est assis dans un fauteuil .\n",
      "prd :  A man with a beard purse on a holding in a field . <eos> . . . . . . . . . . . . <eos>\n",
      "trg :  A man with a name tag on is sitting in a chair .\n",
      "\n",
      "Val_loss : 3.149\n"
     ]
    }
   ],
   "source": [
    "def collate_fn(batch_iter: Iterable):\n",
    "    \"\"\"\n",
    "    Data_loader에서 불러온 데이터를 가공하는 함수\n",
    "    토크나이징 => encoding => 시작 끝을 의미하는 spectial token(<bos>,<eos>) 추가 순으로 진행\n",
    "    \"\"\"\n",
    "    text_transform = {}\n",
    "    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "        text_transform[ln] = utils.sequential_transforms(\n",
    "            token_transform[ln],  # 토크나이징\n",
    "            vocab_transform[ln],  # encoding\n",
    "            utils.tensor_transform, # BOS/EOS를 추가하고 텐서를 생성\n",
    "        )  \n",
    "        # sequential_transform, tensor_transform은 utils.py 참고\n",
    "    \n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch_iter:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample))\n",
    "\n",
    "    # Pad 붙이기\n",
    "    PAD_IDX = 1\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch.T, tgt_batch.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# token을 단어로 바꾸기 위한 dict 생성, vocab의 key와 value 위치 변경\n",
    "# 아래 helper 함수에서 활용됨.\n",
    "decoder_en = {v:k for k,v in vocab_transform['en'].get_stoi().items()}\n",
    "decoder_fr = {v:k for k,v in vocab_transform['fr'].get_stoi().items()}\n",
    "\n",
    "\n",
    "def helper_what_sen(src,trg,logits,i,c=100,sen_num=0) : \n",
    "    '''\n",
    "    문장이 제대로 학습되고 있는지를 확인하는 함수\n",
    "\n",
    "    src = encoding 된 source_sentence \n",
    "    trg = encoding 된 target_sentence\n",
    "    logits = 모델 예측값\n",
    "    i = 현재 batch 순서\n",
    "    c = 결과를 보여주는 단계, ex) c = 100이면 100,200,300... 번째 batch에서 결과를 보여줌\n",
    "    sen_num = batch 내 문장 중 몇 번째 문장을 추적할 것인지 설정\n",
    "    '''\n",
    "    if i % c == 0 and i != 0 :\n",
    "        src_sen = ' '.join([decoder_fr[i] for i in src.tolist()[sen_num] if decoder_fr[i][0] != '<' ])\n",
    "        trg_sen = ' '.join([decoder_en[i] for i in trg.tolist()[sen_num] if decoder_en[i][0] != '<' ])\n",
    "        prediction = logits.max(dim=-1, keepdim=False)[1][sen_num]\n",
    "        prd_sen = ' '.join([decoder_en[i] for i in prediction.tolist() if decoder_en[i] != '<' ])\n",
    "        '''\n",
    "        /*/* 모델의 예측 문장(prd_sen)을 구하는 방법 /*/* \n",
    "\n",
    "        n = batch size, trg_token_len = batch 내 문장의 최대 토큰 개수\n",
    "\n",
    "        모델 output(=logits)은 (n, trg_token_len, trg_vocab_len)의 3차원 텐서임.\n",
    "\n",
    "        1. 해당 텐서를 trg_vocab_len 차원의 기준으로 max를 하면 (n,trg_token_len)을 반환\n",
    "        2. tensor.max()의 수행 결과는 [최댓값,idx]를 반환함.\n",
    "        3. [1]을 넣어 idx를 선택, 그 결과는 (n, trg_token_len) 차원의 idx 반환\n",
    "        4. 원하는 문장 순서(sen_num)을 선택한 뒤 정수를 다시 단어로 decoding 수행\n",
    "        \n",
    "\n",
    "        '''\n",
    "\n",
    "        print('')\n",
    "        print(f'{i}번째 batch에 있는 {sen_num}번째 문장 예측 결과 확인')\n",
    "        print('src : ',src_sen)\n",
    "        print('prd : ',prd_sen)\n",
    "        print('trg : ',trg_sen)\n",
    "        print('')\n",
    "\n",
    "    return None\n",
    "\n",
    "def evaluate(model):\n",
    "    #모델 평가모드 \n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    \n",
    "    # Load_Dataset\n",
    "    dataset= fr_to_en(set_type='validation')\n",
    "\n",
    "    # validation 데이터 불러오기\n",
    "    batch_size = 128\n",
    "    val_dataloader = DataLoader(dataset,batch_size,collate_fn=collate_fn)\n",
    "\n",
    "    for i,(src,tgt) in enumerate(val_dataloader) :\n",
    "        \n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        tgt_input = tgt[:,:-1]\n",
    "\n",
    "        logits = model(src,tgt_input)\n",
    "\n",
    "        helper_what_sen(src,tgt_input,logits,i,2,0) # 학습상태 확인\n",
    "\n",
    "        tgt_output = tgt[:,1:]\n",
    "        loss = loss_fn(logits.reshape(-1,logits.shape[-1]),tgt_output.reshape(-1))\n",
    "\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(val_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "##### Validation으로 테스트하기\n",
    "\n",
    "### 출력 문장수를 조정하고 싶으면 helper_what_sen의 parameter 수정\n",
    "\n",
    "val_loss = evaluate(model)\n",
    "print(f'Val_loss : {val_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 직접 문장 테스트하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장 생성 완료\n",
      "1차 A young woman in a person is standing on the air\n",
      "2차 A people people is a field is riding in a street with\n"
     ]
    }
   ],
   "source": [
    "def tokenizing_src(input_data:str) : \n",
    "    # input_data_tokenizing\n",
    "    token_data = token_transform['fr'](input_data)\n",
    "    vocab_src = vocab_transform['fr'](token_data)\n",
    "    tokenized_src = [2] + vocab_src + [3]\n",
    "    return tokenized_src\n",
    "\n",
    "\n",
    "def test(model, input_data, max_length = 40) :\n",
    "    '''\n",
    "    max_length = token 최대 크기\n",
    "    '''\n",
    "    # Input 토크나이징 \n",
    "    tokenized_input = tokenizing_src(input_data)\n",
    "\n",
    "    # src Tensor에 Token 저장\n",
    "    src = torch.LongTensor(tokenized_input).unsqueeze(0).to(device)\n",
    "\n",
    "    # trg Tensor 생성(1, max_length)\n",
    "    trg = torch.zeros(1,max_length).type_as(src.data).to(device)\n",
    "\n",
    "    # src encoding 하기 \n",
    "    enc_src = model.encode(src)\n",
    "\n",
    "    next_trg = 2 # 문장 시작 <bos> idx\n",
    "    for i in range(0,max_length) :\n",
    "        trg[0][i] = next_trg # token 저장\n",
    "\n",
    "        logits = model.decode(src,trg,enc_src) # output 산출\n",
    "\n",
    "        prd = logits.squeeze(0).max(dim=-1, keepdim=False)[1] # 예측 단어 중 max 추출\n",
    "        next_word = prd.data[i] # i 번째 위치한 단어 추출\n",
    "        next_trg = next_word.item() \n",
    "        if next_trg == 3 :\n",
    "            # <eos> 나오면 종료\n",
    "            print('문장 생성 완료')\n",
    "            trg[0][i] = next_trg\n",
    "            break\n",
    "    \n",
    "    # <pad> 제거\n",
    "    eos_idx = int(torch.where(trg[0] == 3)[0][0])\n",
    "    trg = trg[0][:eos_idx].unsqueeze(0)\n",
    "\n",
    "    # 번역\n",
    "    translation = [decoder_en[i] for i in trg.squeeze(0).tolist()]\n",
    "    print('1차',' '.join(translation[1:]))\n",
    "\n",
    "    # 다시 모델에 넣음\n",
    "    new_trg = model(src, trg)\n",
    "    new_trg = new_trg.squeeze(0).max(dim=-1)[1]\n",
    "\n",
    "    # 번역\n",
    "    translation = [decoder_en[i] for i in new_trg.tolist()]\n",
    "    print('2차',' '.join(translation))\n",
    "\n",
    "    return translation\n",
    "\n",
    "\n",
    "a = test(model,\"je suis étudiant .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{386: ('Jeune garçon et un homme plus âgé qui attendent de payer.',\n",
       "  'Young boy and an older man waiting to check out.'),\n",
       " 467: (\"Jeune homme s'exhibant en effectuant un mouvement de karaté pour surprendre une fille.\",\n",
       "  'Young man showing off by performing a karate move for surprised girl.'),\n",
       " 1408: ('Jeune fille glisse sur un toboggan gonflé',\n",
       "  'Young girl sliding down an inflated slide'),\n",
       " 1629: ('Un homme dans une camisole essaie de se détacher debout devant un enfant avec des blocs Jenga.',\n",
       "  'Man in straight jacket trying to get loose, standing in front of child with Jenga blocks.'),\n",
       " 1962: (\"Jeune garçon en tenue de baseball s'agenouillant pour attraper une balle sur un terrain de baseball.\",\n",
       "  'Young boy in baseball uniform kneeling to catch a ball on a baseball field.'),\n",
       " 2373: ('Un homme conduisant une Jeep verte franchit de gros rochers.',\n",
       "  'A man driving a green jeep is crossing over large rocks.'),\n",
       " 2732: ('Je pense que les travaux de construction se passent ici.',\n",
       "  'I think the construction work is going on here.'),\n",
       " 4593: ('Un homme japonais en T-shirt rouge, jouant au tennis lors des Jeux Olympiques.',\n",
       "  'A Japanese man in a red shirt, at the olympics playing tennis.'),\n",
       " 6454: (\"Un soldat assis sur le toit d'une Jeep tenant une mitraillette, et un soldat assis à l'intérieur.\",\n",
       "  'Soldier sitting on top of Jeep holding a machine gun and soldier sitting inside.'),\n",
       " 6797: ('Une femme, en chemise rose, joue le Jenga, tandis que deux jeunes adultes regardent.',\n",
       "  'A woman, in the pink shirt, is playing Jenga, while two young adults watch.'),\n",
       " 7456: ('Je vais à une compétition de hot-dog à Coney Island.',\n",
       "  'I am going to a hotdog competition in Coney Island.'),\n",
       " 8342: ('Des filles en bikinis rouges exécutent une chorégraphie lors des Jeux olympiques de 2008.',\n",
       "  'Girls in red bikinis do a dance routine at the 2008 Olympics.'),\n",
       " 12022: (\"Jeune femme peint le visage d'une autre jeune femme à l'extérieur.\",\n",
       "  'Young lady paints another young ladies face outdoors.'),\n",
       " 12221: (\"Jeune garçon habillé d'un maillot blanc saute dans la piscine.\",\n",
       "  'Young boy wearing a white bathing suit is jumping up in the pool.'),\n",
       " 12587: ('Un homme au milieu du rayon des magazines féminins lit un magazine qui dit : \"Je suis enceinte !\"',\n",
       "  'A man in the middle of the section for women\\'s lifestyle magazines reads a magazine that declares \"I \\'m Pregnant!\"'),\n",
       " 19365: ('Une fille asiatique jouant au Jenga et craignant que les pièces tombent.',\n",
       "  'Asian girl playing Jenga fearing that the pieces will fall over.'),\n",
       " 20781: ('Un jeune couple commence une partie de Jenga sur une table basse dans le salon.',\n",
       "  'A young couple are at the beginning of playing Jenga on a living room coffee table.'),\n",
       " 22284: (\"Une femme asiatique en compétition lors des Jeux olympiques d'hiver.\",\n",
       "  'An Asian women competing in the winter Olympics.'),\n",
       " 24150: ('Jermaine de \"Flight of the Conchords\" en train d\\'enseigner les mathématiques dans un pays étranger.',\n",
       "  'Jermaine from flight of the Concords teaching math in a foreign country.'),\n",
       " 24670: ('Un nouveau-né vêtu d\\'un maillot où est écrit : \"Je suis le patron\".',\n",
       "  'A newborn wearing a shirt that says, \"I am the boss.\"'),\n",
       " 24744: ('Je vois un groupe de personnes et un policier qui sont là',\n",
       "  'I see a group of people standing around and a policeman standing around.'),\n",
       " 24806: (\"Un groupe d'étudiants faisant une partie de Jenga.\",\n",
       "  'A college group of students playing a game of Jenga.'),\n",
       " 26206: ('Deux enfants jouent au Jenga sur un plancher en bois.',\n",
       "  'Two children play Jenga on a wooden floor.'),\n",
       " 26297: ('Un homme et une femme en tenues semi-professionnelles affichent des visages enthousiastes derrière une table où sont éparpillés des blocs de Jenga.',\n",
       "  'A man and a woman dressed in semi-formal attire show faces of excitement looking over a table with Jenga blocks scattered over it.'),\n",
       " 27591: ('Un vieil homme porte la flamme olympique pour les Jeux olympiques de 2012 à Londres devant un groupe de spectateurs.',\n",
       "  'An older man carries the Olympic Torch for the London 2012 Olympics past a group of spectators.'),\n",
       " 27887: ('Un match de volley féminin aux Jeux Olympiques est très intense.',\n",
       "  \"Women's volleyball at the Olympics is very intense.\"),\n",
       " 27918: ('Six hommes font une course pendant les Jeux olympiques de Londres en 2012.',\n",
       "  'Six men are running a race during the 2012 London Olympics.'),\n",
       " 27932: ('Une fille lors du tournoi de beach volley des Jeux olympiques de Londres en 2012.',\n",
       "  'A girl in the VolleyBall challenge, at the 2012 London Olympics.'),\n",
       " 27944: ('Quatre athlètes féminines jouent au beach volley lors des Jeux olympiques de Londres en 2012.',\n",
       "  'Four female athletes play beach volleyball at the London 2012 Olympics.'),\n",
       " 28032: (\"Deux personnes faisant de l'escrime aux Jeux olympiques de Londres en 2012.\",\n",
       "  'Two people fencing at the 2012 London Olympics.'),\n",
       " 28034: (\"Une course aux Jeux olympiques vue de loin pour montrer l'immense foule.\",\n",
       "  'The Olympics running event shoot from far away to show the massive crowd.'),\n",
       " 28111: ('Un joueur de badminton participe aux Jeux olympiques de Londres en 2012 et saute du sol tout en fouettant sa raquette.',\n",
       "  'A tennis player is competing in the London 2012 Olympics and is leaping off the ground while swinging the racket.')}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_search_src(words='Un homme') -> dict : \n",
    "    df_fr = pd.DataFrame(fr_train)\n",
    "    result = df_fr[df_fr[0].str.contains(words)]\n",
    "\n",
    "    def select_test_item(num) :\n",
    "        return fr_train[num], en_train[num]\n",
    "    \n",
    "\n",
    "    fr_en = {i:select_test_item(i) for i in result.index.tolist()}\n",
    "    return fr_en\n",
    "\n",
    "\n",
    "sen_list = word_search_src('Je')\n",
    "\n",
    "sen_list\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
