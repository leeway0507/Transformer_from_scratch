{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenzier 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Iterable, List\n",
    "from model import transformer\n",
    "from data import fr_to_en\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "\n",
    "\n",
    "### Data_load\n",
    "fr_train = utils.open_text_set(\"data/training/train.fr\")\n",
    "en_train = utils.open_text_set(\"data/training/train.en\")\n",
    "vocab_transform, token_transfrom = utils.make_vocab(fr_train, en_train)\n",
    "\n",
    "decoder_en = {v:k for k,v in vocab_transform['en'].get_stoi().items()}\n",
    "decoder_fr = {v:k for k,v in vocab_transform['fr'].get_stoi().items()}\n",
    "\n",
    "# param\n",
    "SRC_LANGUAGE = \"fr\"\n",
    "TGT_LANGUAGE = \"en\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xavier \n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "# loss_fn\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=1)\n",
    "\n",
    "# optimzer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "def collate_fn(batch_iter: Iterable):\n",
    "    \"\"\"\n",
    "    Data_Loader에서 사용하는 매서드\n",
    "    \"\"\"\n",
    "    text_transform = {}\n",
    "    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "        '''\n",
    "        token_result->vocab_result->tensor_transform\n",
    "\n",
    "        변수를 정한다음 함수쓰듯 값을 넣으면 3번을 연속으로 수행\n",
    "        x = sequntial_transforms(transform)\n",
    "        x('je') => [2,0,3]\n",
    "        '''\n",
    "        text_transform[ln] = utils.sequential_transforms(\n",
    "            token_transfrom[ln],  # 토큰화(Tokenization)\n",
    "            vocab_transform[ln],  # 수치화(Numericalization)\n",
    "            utils.tensor_transform,\n",
    "        )  # BOS/EOS를 추가하고 텐서를 생성\n",
    "    \n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch_iter:\n",
    "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample))\n",
    "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample))\n",
    "\n",
    "    PAD_IDX = 1\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch.T, tgt_batch.T\n",
    "\n",
    "\n",
    "def helper_what_sen(src,trg,logits,i,c=10,sen_num=0) : \n",
    "    if i % c == 0 :\n",
    "        src_sen = ' '.join([decoder_fr[i] for i in src.tolist()[sen_num] if decoder_fr[i][0] != '<' ])\n",
    "        trg_sen = ' '.join([decoder_en[i] for i in trg.tolist()[sen_num] if decoder_en[i][0] != '<' ])\n",
    "        prob = logits.squeeze(0).max(dim=-1, keepdim=False)[1][sen_num]\n",
    "        prd_sen = ' '.join([decoder_en[i] for i in prob.tolist() if decoder_en[i] != '<' ])\n",
    "        print(f'{i}번째 중 {sen_num}번째 문장')\n",
    "        print('src : ',src_sen)\n",
    "        print('prd : ',prd_sen)\n",
    "        print('trg : ',trg_sen)\n",
    "    return None\n",
    "    \n",
    "def train_epoch(model,optimizer) : \n",
    "    model.train()\n",
    "    losses = 0\n",
    "    # Load_Dataset\n",
    "    dataset= fr_to_en(set_type='training')\n",
    "\n",
    "    # Data_loader\n",
    "    batch_size = 128\n",
    "    train_dataloader = DataLoader(dataset,batch_size,collate_fn=collate_fn)\n",
    "\n",
    "    j = [i for i in train_dataloader]\n",
    "\n",
    "    # for src,tgt in j[:3] :\n",
    "    for i,(src,tgt) in enumerate(train_dataloader) :\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        logits = model(src,tgt)\n",
    "        helper_what_sen(src,tgt,logits,i)\n",
    "        optimizer.zero_grad()\n",
    "        # tgt_out = tgt[1:,:]\n",
    "        loss = loss_fn(logits.reshape(-1,logits.shape[-1]),tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(train_dataloader)\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    # Load_Dataset\n",
    "    dataset= fr_to_en(set_type='validation')\n",
    "\n",
    "    # Data_loader\n",
    "    batch_size = 128\n",
    "    val_dataloader = DataLoader(dataset,batch_size,collate_fn=collate_fn)\n",
    "\n",
    "    for i,(src,tgt) in enumerate(val_dataloader) :\n",
    "        \n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        logits = model(src,tgt)\n",
    "\n",
    "        helper_what_sen(src,tgt,logits,i)\n",
    "        \n",
    "        loss = loss_fn(logits.reshape(-1,logits.shape[-1]),tgt.reshape(-1))\n",
    "\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(val_dataloader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련이 잘되고 있는지 확인하는 helper 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper_what_sen(src,trg,logits,i,c=10,sen_num=0) : \n",
    "    if i % c == 0 :\n",
    "        src_sen = ' '.join([decoder_fr[i] for i in src.tolist()[sen_num] if decoder_fr[i][0] != '<' ])\n",
    "        trg_sen = ' '.join([decoder_en[i] for i in trg.tolist()[sen_num] if decoder_en[i][0] != '<' ])\n",
    "        prob = logits.squeeze(0).max(dim=-1, keepdim=False)[1][0]\n",
    "        prd_sen = ' '.join([decoder_en[i] for i in prob.tolist() if decoder_en[i] != '<' ])\n",
    "        print(f'{i}번째 중 {sen_num}번째 문장')\n",
    "        print('src : ',src_sen)\n",
    "        print('prd : ',prd_sen)\n",
    "        print('trg : ',trg_sen)\n",
    "    return None\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    # Load_Dataset\n",
    "    dataset= fr_to_en(set_type='validation')\n",
    "\n",
    "    # Data_loader\n",
    "    batch_size = 128\n",
    "    val_dataloader = DataLoader(dataset,batch_size,collate_fn=collate_fn)\n",
    "\n",
    "    for i,(src,tgt) in enumerate(val_dataloader) :\n",
    "        \n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        logits = model(src,tgt)\n",
    "        helper_what_sen(src,tgt,logits,i,c=1)\n",
    "        loss = loss_fn(logits.reshape(-1,logits.shape[-1]),tgt.reshape(-1))\n",
    "        if i % 10 == 0 :\n",
    "            global logits_2\n",
    "            logits_2 =logits\n",
    "\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(val_dataloader)\n",
    "# prob = logits.squeeze(0).max(dim=-1, keepdim=False)[1] # logits.reshape(-1,logits.shape[-1])[1] 이거와 결과가 같네;; 신기하네"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3840])\n",
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "print(logits_2.reshape(-1,logits_2.shape[-1]).max(dim=1)[0].size())\n",
    "\n",
    "print(logits_2.squeeze(0).max(dim=-1, keepdim=False)[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-26.6254, -30.9601,   0.0000,  ..., -29.1219, -29.2782, -27.4871],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prob = logits_2.reshape(-1,logits_2.shape[-1]).max(dim=1)[-1]\n",
    "\n",
    "print(logits_2.reshape(-1,logits_2.shape[-1])[0])\n",
    "# prd_sen = ' '.join([decoder_en[i] for i in prob.tolist() if decoder_en[i] != '<' ])\n",
    "\n",
    "# prd_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([118, 33])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is validation\n",
      "0번째 중 0번째 문장\n",
      "src :  Un groupe d' hommes chargent du coton dans un camion\n",
      "prd :  <bos> A group of men are fighting attempts onto a truck <eos> 2012 2012 2012 2012 2012 2012 <eos> 2012 2012 2012 2012 2012 gain gain 2012 2012 2012 2012\n",
      "trg :  A group of men are loading cotton onto a truck\n",
      "1번째 중 0번째 문장\n",
      "src :  Un homme dans un petit bateau blanc sur un lac .\n",
      "prd :  <bos> Man in a small white boat on a lake . <eos> 2012 2012 2012 scoop 2012 2012 2012 2012 2012 2012 2012 substance 2012 2012 2012 substance 2012 2012 2012\n",
      "trg :  Man in a small white boat on a lake .\n",
      "2번째 중 0번째 문장\n",
      "src :  Un chien noir dans l' herbe , tenant un objet en plastique blanc dans sa gueule .\n",
      "prd :  <bos> A black dog standing in some grass holding a white plastic palm in its mouth . <eos> complex 2012 substance 2012 2012 2012 substance substance 2012 2012 puck substance 2012 gain\n",
      "trg :  A black dog standing in some grass holding a white plastic item in its mouth .\n",
      "3번째 중 0번째 문장\n",
      "src :  Deux garçons à l' intérieur d' un espace clos sautent en l' air tout en tenant un ballon de basket .\n",
      "prd :  <bos> Two boys inside a fence jump in the air while holding a basketball . <eos> <eos> defends 2012 2012 substance 2012 2012 2012 2012 2012 2012\n",
      "trg :  Two boys inside a fence jump in the air while holding a basketball .\n",
      "4번째 중 0번째 문장\n",
      "src :  Le chien noir saute au-dessus de l' eau vers un frisbee flottant près d' un bateau .\n",
      "prd :  <bos> The black dog jumps above the water towards a Frisbee deep near a boat . <eos> 2012 2012 2012 2012 2012 2012 2012 2012 substance 2012 2012 2012 pan substance 2012 2012 2012\n",
      "trg :  The black dog jumps above the water towards a Frisbee floating near a boat .\n",
      "5번째 중 0번째 문장\n",
      "src :  Un vieil homme est assis avec un plateau sur ses genoux .\n",
      "prd :  <bos> An old man sits with a kayak in his lap . <eos> complex 2012 2012 2012 substance 2012 2012 2012 substance substance 2012 substance 2012 2012 2012\n",
      "trg :  An old man sits with a tray in his lap .\n",
      "6번째 중 0번째 문장\n",
      "src :  Un homme avec un badge est assis dans un fauteuil .\n",
      "prd :  <bos> A man with a <unk> himself on is sitting in a chair . <eos> 2012 <eos> <eos> 2012 2012 2012 2012 2012 2012 substance 2012 2012 gain\n",
      "trg :  A man with a name tag on is sitting in a chair .\n",
      "7번째 중 0번째 문장\n",
      "src :  Un jeune garçon montre son collier de perles marron et vertes .\n",
      "prd :  <bos> A young boy shows his brown and green maroon <unk> . <eos> 2012 2012 gain opponents 2012 2012 2012 2012 2012 2012 2012 <eos> 2012 2012 gain substance substance 2012 2012 2012\n",
      "trg :  A young boy shows his brown and green bead necklace .\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load('model/model3.pt',map_location=torch.device('cpu'))\n",
    "model.device = 'cpu'\n",
    "model.eval()\n",
    "\n",
    "val_loss = evaluate(model)\n",
    "\n",
    "# from timeit import default_timer as timer\n",
    "# NUM_EPOCHS = 1\n",
    "\n",
    "# for epoch in range(1, NUM_EPOCHS+1):\n",
    "#     start_time = timer()\n",
    "#     train_loss = train_epoch(model, optimizer)\n",
    "#     end_time = timer()\n",
    "#     val_loss = evaluate(model)\n",
    "#     print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_Parameter\n",
      "{'src_vocab_size': 11509, 'trg_vocab_size': 10837, 'src_pad_idx': 1, 'trg_pad_idx': 1, 'embed_size': 512, 'num_layers': 3, 'forward_expansion': 2, 'heads': 8, 'dropout': 0.1, 'device': 'cpu', 'max_length': 140}\n",
      "5 5\n",
      "1 5\n",
      "1 5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[2, 8, 5, 64]' is invalid for input of size 2560",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_len\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   memory\u001b[39m=\u001b[39m b\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m   out \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdecode(src,ys,memory)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   _, next_word \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(out,dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   next_word \u001b[39m=\u001b[39m next_word\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;32m/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb 셀 7\u001b[0m in \u001b[0;36mntransformer.decode\u001b[0;34m(self, src, trg, enc_src)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=335'>336</a>\u001b[0m src_trg_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_pad_mask(trg, src)  \u001b[39m# Decoder Input에 대한 masking 필요\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=336'>337</a>\u001b[0m trg_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_trg_mask(trg)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=337'>338</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mDecoder(trg, enc_src, src_trg_mask, trg_mask)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=338'>339</a>\u001b[0m \u001b[39m# Linear Layer\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=339'>340</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_out(out)  \u001b[39m# num of sentence x max_length x trg_vocab_size\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb 셀 7\u001b[0m in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, enc_out, src_trg_mask, trg_mask)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=279'>280</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embedding(x) \u001b[39m+\u001b[39m pos_embed)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=280'>281</a>\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=281'>282</a>\u001b[0m     \u001b[39m# Decoder Input, Encoder K, Encoder V , src_trg_mask, trg_mask\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=282'>283</a>\u001b[0m     out \u001b[39m=\u001b[39m layer(out, enc_out, enc_out, src_trg_mask, trg_mask)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=283'>284</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb 셀 7\u001b[0m in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x, value, key, src_trg_mask, target_mask)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=222'>223</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(attention \u001b[39m+\u001b[39m x))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=224'>225</a>\u001b[0m \u001b[39m# encoder_decoder attention + feed_forward\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=225'>226</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder_block(value, key, query, src_trg_mask)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=226'>227</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb 셀 7\u001b[0m in \u001b[0;36mEncoderBlock.forward\u001b[0;34m(self, value, key, query, mask)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, value, key, query, mask):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=123'>124</a>\u001b[0m     \u001b[39m# self Attention\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m     attention \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(value, key, query, mask)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m     \u001b[39m# Add & Normalization\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=126'>127</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(attention \u001b[39m+\u001b[39m query))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb 셀 7\u001b[0m in \u001b[0;36mselfAttention.forward\u001b[0;34m(self, value, key, query, mask)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m key_len \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]  \u001b[39m# token 개수\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m query_len \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]  \u001b[39m# token 개수\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39;49mreshape(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     N_batch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mheads, value_len, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhead_dim\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m )  \u001b[39m# (n x h x value_len x d_k)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m key \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     N_batch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads, key_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m )  \u001b[39m# (n x h x key_len x d_k)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m query \u001b[39m=\u001b[39m query\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     N_batch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheads, query_len, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhead_dim\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yangwoolee/git_repo/transformer_from_scratch/Transformer_From_Scratch.ipynb#X24sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m )  \u001b[39m# (n x h x query_len x d_k)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[2, 8, 5, 64]' is invalid for input of size 2560"
     ]
    }
   ],
   "source": [
    "src = torch.tensor([[2,2012, 4805, 1536,3]])\n",
    "ys = torch.ones(1, 1).fill_(2).type(torch.long)\n",
    "b = model.encode(src)\n",
    "max_len = 10\n",
    "for i in range(max_len-1):\n",
    "  memory= b\n",
    "  out = model.decode(src,ys,memory)\n",
    "  _, next_word = torch.max(out,dim=-1)\n",
    "  next_word = next_word.item()\n",
    "  ys = torch.cat([ys,\n",
    "                  torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "  if next_word == 3:\n",
    "      break\n",
    "print(ys)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param\n",
    "SRC_LANGUAGE = \"fr\"\n",
    "TGT_LANGUAGE = \"en\"\n",
    "\n",
    "with open('config/transformer.json', 'r') as file:\n",
    "    param = json.load(file)\n",
    "    print('Model_Parameter')\n",
    "    print(param)    \n",
    "model = ntransformer(**param)\n",
    "\n",
    "def train_epoch(model,optimizer) : \n",
    "    model.train()\n",
    "    losses = 0\n",
    "    # Load_Dataset\n",
    "    dataset= fr_to_en(set_type='training')\n",
    "\n",
    "    # Data_loader\n",
    "    batch_size = 128\n",
    "    train_dataloader = DataLoader(dataset,batch_size,collate_fn=collate_fn)\n",
    "\n",
    "    j = [i for i in train_dataloader]\n",
    "\n",
    "    # for src,tgt in train_dataloader :\n",
    "    for src,tgt in train_dataloader :\n",
    "        \n",
    "        # tgt_input = tgt[:, :-1]\n",
    "        logits = model(src,tgt)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # tgt_out = tgt[:,1:]\n",
    "        loss = loss_fn(logits.reshape(-1,logits.shape[-1]),tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "\n",
    "    return losses / len(train_dataloader)\n",
    "        \n",
    "\n",
    "train_loss = train_epoch(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'suis'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_to_en(result) :\n",
    "    encoding_val = result.argmax().item()\n",
    "    return decoder_en[encoding_val]\n",
    "\n",
    "def decode_to_fr(result) :\n",
    "    if type(result) == torch.Tensor() :\n",
    "        encoding_val = result.argmax().item()\n",
    "    elif type(result) == int :\n",
    "        encoding_val = result\n",
    "    return decoder_fr[encoding_val]\n",
    "\n",
    "\n",
    "decode_to_en(b)\n",
    "decode_to_fr(4805)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56, 108]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transform['fr'](['bleu','vert'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 진행\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.730595707893372"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    # Load_Dataset\n",
    "    dataset= fr_to_en(set_type='validation')\n",
    "\n",
    "    # Data_loader\n",
    "    batch_size = 128\n",
    "    val_dataloader = DataLoader(dataset,batch_size,collate_fn=collate_fn)\n",
    "\n",
    "    for i,(src,tgt) in enumerate(val_dataloader) :\n",
    "        tgt_input = tgt[:, :-1]\n",
    "        \n",
    "        logits = model(src,tgt)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[:,1:]\n",
    "        loss = loss_fn(logits.reshape(-1,logits.shape[-1]),tgt.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        if i % 20 == 0 :\n",
    "            print(f'{i}번째 진행')\n",
    "    return losses / len(val_dataloader)\n",
    "\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate output sequence using greedy algorithm\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys,\n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "# actual function to translate input sentence into target language\n",
    "def translate(model: torch.nn.Module, src_sentence: str):\n",
    "    model.eval()\n",
    "    text_transform = {}\n",
    "    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "        text_transform[ln] = ut.sequential_transforms(\n",
    "            token_transfrom[ln],  # 토큰화(Tokenization)\n",
    "            vocab_transform[ln],  # 수치화(Numericalization)\n",
    "            ut.tensor_transform,\n",
    "        )  # BOS/EOS를 추가하고 텐서를 생성\n",
    "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    model(src)\n",
    "\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2012, 4805, 1536]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (default, Jun 13 2022, 17:35:03) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
