{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "from konlpy.tag import Hannanum\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "# model = ElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "# tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_toc</th>\n",
       "      <th>book_intro</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>한 권으로 끝내는 메타버스 크리에이터</td>\n",
       "      <td>['메타버스란', '왜 메타버스인가', '메타버스의 유형을 알아보자', '메타버스 ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do it! 점프 투 파이썬: 라이브러리 예제 편</td>\n",
       "      <td>['', '텍스트 다루기', '문자열을 줄여 표시하려면 textwrap shorte...</td>\n",
       "      <td>['이 책은 Do it 점프 투 파이썬 의 박응용 저자가 그동안 수많은 독자에게 받...</td>\n",
       "      <td>['실무에서 자주 쓰는 파이썬 라이브러리는 다 있다 필수 파이썬 라이브러리 개 엄선...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    book_title  \\\n",
       "0         한 권으로 끝내는 메타버스 크리에이터   \n",
       "1  Do it! 점프 투 파이썬: 라이브러리 예제 편   \n",
       "\n",
       "                                            book_toc  \\\n",
       "0  ['메타버스란', '왜 메타버스인가', '메타버스의 유형을 알아보자', '메타버스 ...   \n",
       "1  ['', '텍스트 다루기', '문자열을 줄여 표시하려면 textwrap shorte...   \n",
       "\n",
       "                                          book_intro  \\\n",
       "0                                                 []   \n",
       "1  ['이 책은 Do it 점프 투 파이썬 의 박응용 저자가 그동안 수많은 독자에게 받...   \n",
       "\n",
       "                                           publisher  \n",
       "0                                                 []  \n",
       "1  ['실무에서 자주 쓰는 파이썬 라이브러리는 다 있다 필수 파이썬 라이브러리 개 엄선...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('data/raw_book_info_list.csv',index_col=0)\n",
    "\n",
    "raw_data.head(2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [데이터 전처리] 단어 키워드 추출에 맞는 Input 데이터 생산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 도서 정보를 하나의 string으로 넣기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환한 도서정보 :  Do it! 점프 투 파이썬: 라이브러리 예제 편\n"
     ]
    }
   ],
   "source": [
    "def Merge_Series_to_str(series:pd.Series) -> str:\n",
    "\n",
    "    '''\n",
    "    column 내 list 자료형이 있을 때, csv 저장 시 str 타입으로 저장됨.\n",
    "    ast.literal_eval 매서드를 새용해 str -> list로 다시 전환하는 매서드 추가\n",
    "\n",
    "    type = 'str' 모든 문장을 하나의 string으로 저장\n",
    "    type = 'list' 모든 문장을 하나의 list로 저장\n",
    "\n",
    "    '''\n",
    "    val_array = series.values\n",
    "\n",
    "    lst = []\n",
    "    for item in val_array :\n",
    "        if item[0] == '[' :\n",
    "            item = ast.literal_eval(item)\n",
    "            lst.extend(item)\n",
    "        else :\n",
    "            lst.append(item)\n",
    "\n",
    "    # 리스트 내 ''제거\n",
    "    lst = list(filter(None,lst))\n",
    "\n",
    "    print('변환한 도서정보 : ',lst[0])\n",
    "    \n",
    "    return re.sub(r'[^\\w\\s]', '', ' '.join(lst))\n",
    "# 1100 파이토치 딥러닝 프로젝트 모음집\n",
    "# 132 엑셀로 하는 데이터 분석\n",
    "# 1 Do it! 점프 투 파이썬: 라이브러리 예제 편\n",
    "# 3 그림과 실습으로 배우는 도커 & 쿠버네티스\n",
    "book_info :str = Merge_Series_to_str(raw_data.iloc[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 일부 영단어를 한글로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변환 : date  =>  날짜\n",
      "변환 : json  =>  제이슨\n",
      "변환 : json  =>  제이슨\n",
      "변환 : server  =>  서버\n",
      "변환 : cafe  =>  카페\n",
      "변환 : naver  =>  네이버\n",
      "변환 : github  =>  깃허브\n"
     ]
    }
   ],
   "source": [
    "def trans_engwords_to_hanwords(words: str) -> list:\n",
    "    # result = 문자열 복사\n",
    "    result = words.split()\n",
    "    EngToKorDict = pd.read_csv(\"data/englist.csv\")\n",
    "    for i in range(len(result)):\n",
    "        lower_case = result[i].lower()\n",
    "        if lower_case in EngToKorDict['eng'].tolist() :\n",
    "            \n",
    "            eng_to_kor= EngToKorDict[EngToKorDict['eng'] == lower_case]['kor'].values[0]\n",
    "            print('변환 :', lower_case,' => ',eng_to_kor)\n",
    "            result[i] = eng_to_kor\n",
    "    return result\n",
    "\n",
    "\n",
    "book_info_trans = trans_engwords_to_hanwords(book_info)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 문장 내 영단어 제거 및 영단어 모아두기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 문자 리스트 추출\n",
    "def find_han_words(text: str) -> list:\n",
    "    return re.findall(\"[\\u3130-\\u318F\\uAC00-\\uD7A3]+\", text)\n",
    "\n",
    "def find_eng_words(text: str) -> list:\n",
    "    return re.findall(\"[a-zA-Z]+\", text)\n",
    "\n",
    "book_info_han = find_han_words(' '.join(book_info_trans))\n",
    "book_info_eng = find_eng_words(' '.join(book_info_trans))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konlpy로 명사만 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "\n",
    "han = Hannanum()\n",
    "\n",
    "# str or list에 따른 tokenizing 방법\n",
    "if type(book_info_han) == list :\n",
    "    han_nouns = han.nouns(' '.join(book_info_trans))\n",
    "    \n",
    "else :\n",
    "    print('book_info type must be list.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문장을 대표할 후보 단어 고르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 내 단어에 대한 value_counts\n",
    "candidates = pd.DataFrame(han_nouns)[0].value_counts() \n",
    "\n",
    "# 3개 이상인 단어만 추출\n",
    "candidate_words = candidates[candidates > 2].index.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformer로 유사도 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/yangwoolee/.cache/torch/sentence_transformers/monologg_koelectra-base-v3-discriminator. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at /Users/yangwoolee/.cache/torch/sentence_transformers/monologg_koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('monologg/koelectra-base-v3-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>공식</th>\n",
       "      <td>0.894798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>시간</th>\n",
       "      <td>0.842275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>개발자</th>\n",
       "      <td>0.795263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>깃허브</th>\n",
       "      <td>0.789461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>바이너리</th>\n",
       "      <td>0.773035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>사용</th>\n",
       "      <td>0.751710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>파이썬</th>\n",
       "      <td>0.749490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>저장</th>\n",
       "      <td>0.722581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>병렬</th>\n",
       "      <td>0.715430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>때</th>\n",
       "      <td>0.697340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>자료</th>\n",
       "      <td>0.660653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>중요</th>\n",
       "      <td>0.650219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>예제</th>\n",
       "      <td>0.650068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>것</th>\n",
       "      <td>0.645680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>실행</th>\n",
       "      <td>0.632354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문자열</th>\n",
       "      <td>0.632100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>비교</th>\n",
       "      <td>0.629967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>라이브러리</th>\n",
       "      <td>0.626609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>압축</th>\n",
       "      <td>0.621575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>데이터</th>\n",
       "      <td>0.615062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "공식     0.894798\n",
       "시간     0.842275\n",
       "개발자    0.795263\n",
       "깃허브    0.789461\n",
       "바이너리   0.773035\n",
       "사용     0.751710\n",
       "파이썬    0.749490\n",
       "저장     0.722581\n",
       "병렬     0.715430\n",
       "때      0.697340\n",
       "자료     0.660653\n",
       "중요     0.650219\n",
       "예제     0.650068\n",
       "것      0.645680\n",
       "실행     0.632354\n",
       "문자열    0.632100\n",
       "비교     0.629967\n",
       "라이브러리  0.626609\n",
       "압축     0.621575\n",
       "데이터    0.615062"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "doc_embedding = model.encode([' '.join(book_info_han)])\n",
    "candidate_embeddings = model.encode(candidate_words)\n",
    "\n",
    "distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
    "pd.DataFrame(distances.T,index=candidate_words).sort_values(by=0,ascending=False)[:20]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 고민\n",
    "tokenizing 하지 않은 오리지널 문장을 docs로 두어야할 것인지\n",
    "\n",
    "아니면 tokenizing한 문장을 docs로 두어야할 것인지.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # max_token_length : 512\n",
    "# tokenizing_docs_original = tokenizer.tokenize(' '.join(book_info_han))\n",
    "# tokenizing_docs_konlpy = tokenizer.tokenize(' '.join(han_nouns))\n",
    "# tokenizing_candidates = tokenizer.tokenize(' '.join(candidate_words))\n",
    "\n",
    "# encoding_original = tokenizer.encode(tokenizing_docs_original,return_tensors=\"pt\")[:1,:512]\n",
    "# encoding_konlpy = tokenizer.encode(tokenizing_docs_konlpy,return_tensors=\"pt\")[:1,:512]\n",
    "# encoding_candidates = tokenizer.encode(tokenizing_candidates,return_tensors=\"pt\")[:1,:512]\n",
    "\n",
    "\n",
    "\n",
    "# electra_original = model(encoding_original)[0].squeeze(0).detach().numpy() # torch.Size([ 512, 768])\n",
    "# electra_konlpy = model(encoding_konlpy)[0].squeeze(0).detach().numpy() # torch.Size([ 512, 768])\n",
    "# electra_candidates = model(encoding_candidates)[0].squeeze(0).detach().numpy() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine 유사도 실험중 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# distance_original = cosine_similarity(electra_original,electra_candidates)\n",
    "# distance_konlpy = cosine_similarity(electra_konlpy,electra_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding_candidates = tokenizer.decode(encoding_candidates[0]).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.732819</td>\n",
       "      <td>0.248315</td>\n",
       "      <td>0.251682</td>\n",
       "      <td>0.253381</td>\n",
       "      <td>0.266203</td>\n",
       "      <td>0.291155</td>\n",
       "      <td>0.268032</td>\n",
       "      <td>0.262364</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.271540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305247</td>\n",
       "      <td>0.297330</td>\n",
       "      <td>0.260703</td>\n",
       "      <td>0.282919</td>\n",
       "      <td>0.281639</td>\n",
       "      <td>0.292454</td>\n",
       "      <td>0.257638</td>\n",
       "      <td>0.271567</td>\n",
       "      <td>0.256121</td>\n",
       "      <td>0.732819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.407831</td>\n",
       "      <td>0.751741</td>\n",
       "      <td>0.672615</td>\n",
       "      <td>0.785368</td>\n",
       "      <td>0.742085</td>\n",
       "      <td>0.445156</td>\n",
       "      <td>0.558662</td>\n",
       "      <td>0.822101</td>\n",
       "      <td>0.807550</td>\n",
       "      <td>0.772749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834117</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.726873</td>\n",
       "      <td>0.668414</td>\n",
       "      <td>0.776618</td>\n",
       "      <td>0.894141</td>\n",
       "      <td>0.830699</td>\n",
       "      <td>0.863877</td>\n",
       "      <td>0.801337</td>\n",
       "      <td>0.407831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.422736</td>\n",
       "      <td>0.836587</td>\n",
       "      <td>0.722945</td>\n",
       "      <td>0.765517</td>\n",
       "      <td>0.875395</td>\n",
       "      <td>0.592998</td>\n",
       "      <td>0.666369</td>\n",
       "      <td>0.884214</td>\n",
       "      <td>0.889834</td>\n",
       "      <td>0.827050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834637</td>\n",
       "      <td>0.768015</td>\n",
       "      <td>0.768665</td>\n",
       "      <td>0.741496</td>\n",
       "      <td>0.795688</td>\n",
       "      <td>0.850251</td>\n",
       "      <td>0.864719</td>\n",
       "      <td>0.846887</td>\n",
       "      <td>0.841673</td>\n",
       "      <td>0.422736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.456230</td>\n",
       "      <td>0.787892</td>\n",
       "      <td>0.832194</td>\n",
       "      <td>0.762701</td>\n",
       "      <td>0.793401</td>\n",
       "      <td>0.909545</td>\n",
       "      <td>0.821563</td>\n",
       "      <td>0.750312</td>\n",
       "      <td>0.726505</td>\n",
       "      <td>0.735523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670517</td>\n",
       "      <td>0.608304</td>\n",
       "      <td>0.683988</td>\n",
       "      <td>0.670515</td>\n",
       "      <td>0.730371</td>\n",
       "      <td>0.673097</td>\n",
       "      <td>0.704872</td>\n",
       "      <td>0.716426</td>\n",
       "      <td>0.704853</td>\n",
       "      <td>0.456230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.465781</td>\n",
       "      <td>0.792797</td>\n",
       "      <td>0.821126</td>\n",
       "      <td>0.874424</td>\n",
       "      <td>0.803995</td>\n",
       "      <td>0.754827</td>\n",
       "      <td>0.897694</td>\n",
       "      <td>0.815088</td>\n",
       "      <td>0.799946</td>\n",
       "      <td>0.821343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751693</td>\n",
       "      <td>0.686573</td>\n",
       "      <td>0.716089</td>\n",
       "      <td>0.710826</td>\n",
       "      <td>0.782929</td>\n",
       "      <td>0.763783</td>\n",
       "      <td>0.775757</td>\n",
       "      <td>0.782943</td>\n",
       "      <td>0.786079</td>\n",
       "      <td>0.465781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.459001</td>\n",
       "      <td>0.731031</td>\n",
       "      <td>0.742773</td>\n",
       "      <td>0.810245</td>\n",
       "      <td>0.757958</td>\n",
       "      <td>0.662624</td>\n",
       "      <td>0.741804</td>\n",
       "      <td>0.796028</td>\n",
       "      <td>0.787598</td>\n",
       "      <td>0.789990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760539</td>\n",
       "      <td>0.752832</td>\n",
       "      <td>0.719729</td>\n",
       "      <td>0.654001</td>\n",
       "      <td>0.785719</td>\n",
       "      <td>0.803183</td>\n",
       "      <td>0.795835</td>\n",
       "      <td>0.831230</td>\n",
       "      <td>0.778022</td>\n",
       "      <td>0.459001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.386041</td>\n",
       "      <td>0.718125</td>\n",
       "      <td>0.682605</td>\n",
       "      <td>0.752835</td>\n",
       "      <td>0.704080</td>\n",
       "      <td>0.460929</td>\n",
       "      <td>0.552803</td>\n",
       "      <td>0.779339</td>\n",
       "      <td>0.767621</td>\n",
       "      <td>0.712863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784960</td>\n",
       "      <td>0.814703</td>\n",
       "      <td>0.704042</td>\n",
       "      <td>0.636094</td>\n",
       "      <td>0.724336</td>\n",
       "      <td>0.820354</td>\n",
       "      <td>0.799081</td>\n",
       "      <td>0.828633</td>\n",
       "      <td>0.753436</td>\n",
       "      <td>0.386041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.391132</td>\n",
       "      <td>0.736671</td>\n",
       "      <td>0.657305</td>\n",
       "      <td>0.740680</td>\n",
       "      <td>0.742986</td>\n",
       "      <td>0.451781</td>\n",
       "      <td>0.552811</td>\n",
       "      <td>0.800931</td>\n",
       "      <td>0.793491</td>\n",
       "      <td>0.725612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836927</td>\n",
       "      <td>0.839299</td>\n",
       "      <td>0.746563</td>\n",
       "      <td>0.660160</td>\n",
       "      <td>0.765709</td>\n",
       "      <td>0.857146</td>\n",
       "      <td>0.844671</td>\n",
       "      <td>0.828408</td>\n",
       "      <td>0.769040</td>\n",
       "      <td>0.391132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.423016</td>\n",
       "      <td>0.721379</td>\n",
       "      <td>0.662757</td>\n",
       "      <td>0.757192</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.461578</td>\n",
       "      <td>0.556925</td>\n",
       "      <td>0.805338</td>\n",
       "      <td>0.792330</td>\n",
       "      <td>0.758737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835353</td>\n",
       "      <td>0.867001</td>\n",
       "      <td>0.745533</td>\n",
       "      <td>0.661098</td>\n",
       "      <td>0.778861</td>\n",
       "      <td>0.891005</td>\n",
       "      <td>0.829942</td>\n",
       "      <td>0.860951</td>\n",
       "      <td>0.784750</td>\n",
       "      <td>0.423016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.732819</td>\n",
       "      <td>0.248315</td>\n",
       "      <td>0.251682</td>\n",
       "      <td>0.253381</td>\n",
       "      <td>0.266203</td>\n",
       "      <td>0.291155</td>\n",
       "      <td>0.268032</td>\n",
       "      <td>0.262364</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.271540</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305247</td>\n",
       "      <td>0.297329</td>\n",
       "      <td>0.260703</td>\n",
       "      <td>0.282919</td>\n",
       "      <td>0.281639</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>0.257638</td>\n",
       "      <td>0.271566</td>\n",
       "      <td>0.256121</td>\n",
       "      <td>0.732819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6    \\\n",
       "0   0.732819  0.248315  0.251682  0.253381  0.266203  0.291155  0.268032   \n",
       "1   0.407831  0.751741  0.672615  0.785368  0.742085  0.445156  0.558662   \n",
       "2   0.422736  0.836587  0.722945  0.765517  0.875395  0.592998  0.666369   \n",
       "3   0.456230  0.787892  0.832194  0.762701  0.793401  0.909545  0.821563   \n",
       "4   0.465781  0.792797  0.821126  0.874424  0.803995  0.754827  0.897694   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "56  0.459001  0.731031  0.742773  0.810245  0.757958  0.662624  0.741804   \n",
       "57  0.386041  0.718125  0.682605  0.752835  0.704080  0.460929  0.552803   \n",
       "58  0.391132  0.736671  0.657305  0.740680  0.742986  0.451781  0.552811   \n",
       "59  0.423016  0.721379  0.662757  0.757192  0.738776  0.461578  0.556925   \n",
       "60  0.732819  0.248315  0.251682  0.253381  0.266203  0.291155  0.268032   \n",
       "\n",
       "         7         8         9    ...       502       503       504       505  \\\n",
       "0   0.262364  0.262900  0.271540  ...  0.305247  0.297330  0.260703  0.282919   \n",
       "1   0.822101  0.807550  0.772749  ...  0.834117  0.844884  0.726873  0.668414   \n",
       "2   0.884214  0.889834  0.827050  ...  0.834637  0.768015  0.768665  0.741496   \n",
       "3   0.750312  0.726505  0.735523  ...  0.670517  0.608304  0.683988  0.670515   \n",
       "4   0.815088  0.799946  0.821343  ...  0.751693  0.686573  0.716089  0.710826   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "56  0.796028  0.787598  0.789990  ...  0.760539  0.752832  0.719729  0.654001   \n",
       "57  0.779339  0.767621  0.712863  ...  0.784960  0.814703  0.704042  0.636094   \n",
       "58  0.800931  0.793491  0.725612  ...  0.836927  0.839299  0.746563  0.660160   \n",
       "59  0.805338  0.792330  0.758737  ...  0.835353  0.867001  0.745533  0.661098   \n",
       "60  0.262364  0.262900  0.271540  ...  0.305247  0.297329  0.260703  0.282919   \n",
       "\n",
       "         506       507       508       509       510       511  \n",
       "0   0.281639  0.292454  0.257638  0.271567  0.256121  0.732819  \n",
       "1   0.776618  0.894141  0.830699  0.863877  0.801337  0.407831  \n",
       "2   0.795688  0.850251  0.864719  0.846887  0.841673  0.422736  \n",
       "3   0.730371  0.673097  0.704872  0.716426  0.704853  0.456230  \n",
       "4   0.782929  0.763783  0.775757  0.782943  0.786079  0.465781  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "56  0.785719  0.803183  0.795835  0.831230  0.778022  0.459001  \n",
       "57  0.724336  0.820354  0.799081  0.828633  0.753436  0.386041  \n",
       "58  0.765709  0.857146  0.844671  0.828408  0.769040  0.391132  \n",
       "59  0.778861  0.891005  0.829942  0.860951  0.784750  0.423016  \n",
       "60  0.281639  0.292453  0.257638  0.271566  0.256121  0.732819  \n",
       "\n",
       "[61 rows x 512 columns]"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(distance_konlpy.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SEP] [CLS] 비명 때문 분 것 수 이미지 설치치 구현 들 프로젝트 결론 다양 실전 이용 파이 클래스 러닝 진행 실험 책 설명 모델 실습한토 소개 관심 등 활용 문제 학습닝 인공지능 설계 머신 이론 딥 데이터 파트원닝 분류 전처 기초 내용 이해 코드론리링 국민 퍼러러셉트 크청롤\n",
      "비명 분치 들 이미지토 것 프로젝트 수셉트 때문 파이 다양 딥 설치 머신 책청롤링 러닝 실습 설명 활용 진행 이용러 퍼 전처 구현 실험닝 국민 크러 등한 데이터 인공지능 기초닝 실전 결론 클래스 모델 이해원 코드론 소개 학습 문제 설계 분류 파트 관심리 이론 내용 [SEP] [CLS]\n"
     ]
    }
   ],
   "source": [
    "# keywords_konlpy = [encoding_candidates[0][index].item() for index in distance_konlpy.argsort()[0]]\n",
    "# keywords_original = [encoding_candidates[0][index].item() for index in distance_original.argsort()[0]]\n",
    "\n",
    "\n",
    "\n",
    "# print(tokenizer.decode(keywords_original))\n",
    "# print(tokenizer.decode(keywords_konlpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformers 원리 이해하기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
